{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38fe9c97",
   "metadata": {},
   "source": [
    "# Hugging Face RVC Training (Colab)\n",
    "\n",
    "This notebook helps you prepare or train a voice model and push it to the Hugging Face Hub. GPU runtime is strongly recommended in Colab.\n",
    "\n",
    "- You can either do zero-shot XTTS (no training) or train an RVC-style model.\n",
    "- After you have a repo on the Hub, link it in the app via Edit Voice → Link Hugging Face Model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4bcb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1: Setup and Imports\n",
    "import os, sys, json, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Core ML/audio\n",
    "import librosa, soundfile as sf\n",
    "\n",
    "# Optionally used downstream\n",
    "try:\n",
    "    import torch, torchaudio\n",
    "except Exception as e:\n",
    "    print(\"Torch/Torchaudio not present yet. Will install in the next cell if needed.\")\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "\n",
    "print({\n",
    "    'python': sys.version,\n",
    "    'numpy': np.__version__,\n",
    "    'pandas': pd.__version__,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f2e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (Colab only)\n",
    "# If running locally, you can skip and use requirements-huggingface.txt\n",
    "try:\n",
    "    import google\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip -q install torch torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "    !pip -q install librosa soundfile huggingface_hub tqdm\n",
    "else:\n",
    "    print(\"Not in Colab: make sure to install deps locally if needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101bb1e0",
   "metadata": {},
   "source": [
    "## Upload/Prepare Training Audio\n",
    "- Provide 2–10 minutes of clean speech.\n",
    "- You can upload a single WAV/MP3 file or a folder of audio clips.\n",
    "- We’ll resample to 22050 Hz and optionally slice into segments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b01dd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "WORKDIR = Path(\"/content\" if 'IN_COLAB' in globals() and IN_COLAB else \".\").resolve()\n",
    "RAW_DIR = WORKDIR / \"voice_raw\"\n",
    "PROC_DIR = WORKDIR / \"voice_proc\"\n",
    "PROC_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(\"Working dir:\", WORKDIR)\n",
    "print(\"Upload or place your training audio into:\", RAW_DIR)\n",
    "RAW_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Helper to process audio\n",
    "TARGET_SR = 22050\n",
    "\n",
    "\n",
    "def convert_and_slice(path, out_dir: Path, target_sr=TARGET_SR, segment_sec=5.0):\n",
    "    y, sr = librosa.load(path, sr=None, mono=True)\n",
    "    if sr != target_sr:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
    "        sr = target_sr\n",
    "    # Normalize\n",
    "    if np.max(np.abs(y)) > 0:\n",
    "        y = y / np.max(np.abs(y))\n",
    "    # Slice\n",
    "    seg_len = int(segment_sec * sr)\n",
    "    count = 0\n",
    "    for i in range(0, len(y), seg_len):\n",
    "        seg = y[i:i+seg_len]\n",
    "        if len(seg) < int(0.5 * seg_len):\n",
    "            continue\n",
    "        out = out_dir / f\"seg_{Path(path).stem}_{count:04d}.wav\"\n",
    "        sf.write(out, seg, sr)\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "# Auto-process any existing files in RAW_DIR\n",
    "files = glob(str(RAW_DIR / \"**/*.*\"), recursive=True)\n",
    "print(\"Found\", len(files), \"raw files\")\n",
    "for f in tqdm(files):\n",
    "    try:\n",
    "        convert_and_slice(f, PROC_DIR)\n",
    "    except Exception as e:\n",
    "        print(\"Skipping\", f, e)\n",
    "\n",
    "print(\"Processed files in:\", PROC_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15a42bb",
   "metadata": {},
   "source": [
    "## Minimal Training Placeholder\n",
    "This notebook shows a minimal placeholder instead of a full RVC pipeline (which is lengthy and repo-specific).\n",
    "We simulate a training artifact by aggregating audio stats and saving a small weights file.\n",
    "\n",
    "You can swap this cell for a community RVC training notebook later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342db5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "WEIGHTS_DIR = WORKDIR / \"weights\"\n",
    "WEIGHTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Aggregate basic stats to simulate a model weights file\n",
    "wav_files = sorted(glob(str(PROC_DIR / \"*.wav\")))\n",
    "print(\"Training on\", len(wav_files), \"segments\")\n",
    "hash_accum = hashlib.sha256()\n",
    "for wf in wav_files:\n",
    "    y, sr = librosa.load(wf, sr=None)\n",
    "    hash_accum.update(y.tobytes())\n",
    "\n",
    "weights_path = WEIGHTS_DIR / \"rvc_placeholder.pth\"\n",
    "with open(weights_path, \"wb\") as f:\n",
    "    f.write(hash_accum.digest())\n",
    "\n",
    "with open(WEIGHTS_DIR / \"README.txt\", \"w\") as f:\n",
    "    f.write(\"Placeholder RVC weights. Replace with real model weights when available.\\n\")\n",
    "\n",
    "print(\"Saved placeholder weights:\", weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bcbb1b",
   "metadata": {},
   "source": [
    "## Push to Hugging Face Hub\n",
    "We will create/reuse a repo and upload the weights folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6122e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, create_repo, upload_folder\n",
    "from getpass import getpass\n",
    "\n",
    "HF_TOKEN = os.environ.get('HF_TOKEN', None)\n",
    "if not HF_TOKEN:\n",
    "    try:\n",
    "        HF_TOKEN = getpass(\"Enter your Hugging Face token (write access): \")\n",
    "    except Exception:\n",
    "        HF_TOKEN = input(\"Enter your Hugging Face token (write access): \")\n",
    "\n",
    "assert HF_TOKEN, \"HF token is required\"\n",
    "\n",
    "REPO_ID = os.environ.get('HF_REPO_ID', 'username/my-voice-rvc')\n",
    "REVISION = os.environ.get('HF_REVISION', 'main')\n",
    "\n",
    "api = HfApi(token=HF_TOKEN)\n",
    "create_repo(repo_id=REPO_ID, token=HF_TOKEN, exist_ok=True, repo_type=\"model\")\n",
    "\n",
    "print(f\"Uploading {WEIGHTS_DIR} to {REPO_ID}@{REVISION}...\")\n",
    "upload_folder(\n",
    "    repo_id=REPO_ID,\n",
    "    folder_path=str(WEIGHTS_DIR),\n",
    "    path_in_repo=\"/\",\n",
    "    repo_type=\"model\",\n",
    "    commit_message=\"Add placeholder RVC weights\",\n",
    "    revision=REVISION,\n",
    "    token=HF_TOKEN,\n",
    ")\n",
    "\n",
    "print(\"✅ Uploaded. Repo:\", f\"https://huggingface.co/{REPO_ID}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
